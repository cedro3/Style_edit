{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Style_edit",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/Style_edit/blob/main/Style_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho2S8T_yJv1Q"
      },
      "source": [
        "# セットアップ1（潜在変数の推定）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuviq3qQkUFy"
      },
      "source": [
        "# 1.tensorflow & Pytorch バージョン変更\n",
        "%tensorflow_version 1.x\n",
        "! pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# 2.githubからコードを取得 & ninja インストール\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'Style_edit' \n",
        "!git clone https://github.com/cedro3/Style_edit.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 3.pSpインストール\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  \n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# 4.学習済みパラメータのダウンロード\n",
        "import os\n",
        "import gdown\n",
        "os.makedirs('pretrained_models', exist_ok=True)\n",
        "gdown.download('https://drive.google.com/u/0/uc?id=1cUv_reLE6k3604or78EranS7XzuVMWeO', 'pretrained_models/e4e_ffhq_encode.pt', quiet=False)\n",
        "\n",
        "# 5.ランドマークデータのダウンロード\n",
        "! wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "! bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# 6.モデルに学習済みパラメータをロード\n",
        "model_path = 'pretrained_models/e4e_ffhq_encode.pt'  \n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVdOZZrTN_um"
      },
      "source": [
        "# セットアップ2（潜在変数の編集）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKA947shEehF"
      },
      "source": [
        "# 1.CLIPインストール\n",
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# 2.学習済みパラメータのダウンロード\n",
        "gdown.download('https://drive.google.com/u/1/uc?id=13CCGLcCw6_GMHe8cUBiaLlORzEK4gwso', 'data_sc.zip', quiet=False)\n",
        "! unzip data_sc.zip\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from MapTS import GetFs,GetBoundary,GetDt\n",
        "from manipulate import Manipulator\n",
        "\n",
        "# 3.CLIPのモデル化\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# 4.モデルに学習済みパラメータをロード\n",
        "M=Manipulator(dataset_name='ffhq')\n",
        "fs3=np.load('./npy/ffhq/fs3.npy')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbN_I_LIOOgr"
      },
      "source": [
        "# 顔画像の切り出し"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBC64FG4Rdux"
      },
      "source": [
        "# --- 画像表示関数 ---\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        if file=='.ipynb_checkpoints':\n",
        "           continue\n",
        "        img = Image.open(folder+'/'+file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(folder+'/'+file, fontsize=15)               \n",
        "    plt.show()\n",
        "    plt.close()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_mHMjhLRxep"
      },
      "source": [
        "# --- サンプル画像表示 ---\n",
        "display_pic('images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ld45KbIF45C"
      },
      "source": [
        "# --- 顔画像の切り出し ---\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "if os.path.isdir('align'):\n",
        "     shutil.rmtree('align')\n",
        "os.makedirs('align', exist_ok=True)\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  import dlib\n",
        "  from utils.alignment import align_face\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor) \n",
        "  return aligned_image \n",
        "\n",
        "files = sorted(os.listdir('./images'))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = run_alignment('./images/'+file)\n",
        "  input_image.resize((256,256))\n",
        "  input_image.save('./align/'+file)\n",
        "\n",
        "display_pic('align')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsgmDCzVOZHy"
      },
      "source": [
        "# 潜在変数の推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxbCdavcfXNd"
      },
      "source": [
        "# --- 潜在変数の推定 ---\n",
        "if os.path.isdir('vec_pic'):\n",
        "     shutil.rmtree('vec_pic')\n",
        "os.makedirs('vec_pic', exist_ok=True)\n",
        "\n",
        "if os.path.isdir('vec'):\n",
        "     shutil.rmtree('vec')\n",
        "os.makedirs('vec', exist_ok=True)\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "files = sorted(os.listdir('./align'))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = Image.open('./align/'+file)\n",
        "  transformed_image = img_transforms(input_image)\n",
        "  with torch.no_grad():\n",
        "     images, latents = net(transformed_image.unsqueeze(0).to('cuda').float(), randomize_noise=False, return_latents=True)\n",
        "     result_image, latent = images[0], latents[0]\n",
        "     tensor2im(result_image).save('./vec_pic/'+file) \n",
        "     torch.save(latents, './vec/'+file[:-4]+'.pt') \n",
        "\n",
        "display_pic('vec_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvA3EJXX3ZxH"
      },
      "source": [
        "# --- 実写と潜在変数の比較 ---\n",
        "display_pic('align')\n",
        "display_pic('vec_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXw0MVRSvV6o"
      },
      "source": [
        "# 潜在変数の編集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG7ZaQnC75qJ"
      },
      "source": [
        "# --- 潜在変数の選択 ---\n",
        "pt_folder = 'vec/'\n",
        "pt_name = '003.pt' #@param {type:\"string\"}\n",
        "latents=torch.load(pt_folder+pt_name)\n",
        "w_plus=latents.cpu().detach().numpy()\n",
        "M.dlatents=M.W2S(w_plus)\n",
        "\n",
        "M.num_images=1\n",
        "M.alpha=[0]\n",
        "M.manipulate_layers=[0]\n",
        "codes,out=M.EditOneC(0,M.dlatents) \n",
        "original=Image.fromarray(out[0,0]).resize((512,512))\n",
        "M.manipulate_layers=None\n",
        "original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1GEXJX82DB"
      },
      "source": [
        "# --- 編集テキスト入力 ---\n",
        "neutral='face' #@param {type:\"string\"}\n",
        "target='smiling face' #@param {type:\"string\"}\n",
        "classnames=[target,neutral]\n",
        "dt=GetDt(classnames,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb-oXMon82QR"
      },
      "source": [
        "# --- alpha & beta の設定 ---\n",
        "beta = 0.1 #@param {type:\"slider\", min:0.08, max:0.3, step:0.01}\n",
        "alpha = 2 #@param {type:\"slider\", min:-10, max:10, step:0.1}\n",
        "M.alpha=[alpha]\n",
        "boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "codes=M.MSCode(M.dlatents,boundary_tmp2)\n",
        "out=M.GenerateImg(codes)\n",
        "generated=Image.fromarray(out[0,0])#.resize((512,512))\n",
        "generated.save('generated.jpg')\n",
        "\n",
        "plt.figure(figsize=(14,7), dpi= 100)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original)\n",
        "plt.title('original')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(generated)\n",
        "plt.title('manipulated')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}