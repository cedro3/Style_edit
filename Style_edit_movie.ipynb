{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Style_edit_movie",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/Style_edit/blob/main/Style_edit_movie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho2S8T_yJv1Q"
      },
      "source": [
        "# セットアップ1（潜在変数の推定）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuviq3qQkUFy"
      },
      "source": [
        "# 1.tensorflow & Pytorch バージョン変更\n",
        "%tensorflow_version 1.x\n",
        "! pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# 2.githubからコードを取得 & ninja インストール\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'Style_edit' \n",
        "!git clone https://github.com/cedro3/Style_edit.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 3.pSpインストール\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  \n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# 4.学習済みパラメータのダウンロード\n",
        "import os\n",
        "import gdown\n",
        "os.makedirs('pretrained_models', exist_ok=True)\n",
        "gdown.download('https://drive.google.com/u/1/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET', 'pretrained_models/e4e_ffhq_encode.pt', quiet=False)\n",
        "\n",
        "# 5.ランドマークデータのダウンロード\n",
        "! wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "! bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# 6.モデルに学習済みパラメータをロード\n",
        "model_path = 'pretrained_models/e4e_ffhq_encode.pt'  \n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVdOZZrTN_um"
      },
      "source": [
        "# セットアップ2（潜在変数の編集）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKA947shEehF"
      },
      "source": [
        "# 1.CLIPインストール\n",
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "# 2.学習済みパラメータのダウンロード\n",
        "gdown.download('https://drive.google.com/u/1/uc?id=13CCGLcCw6_GMHe8cUBiaLlORzEK4gwso', 'data_sc.zip', quiet=False)\n",
        "! unzip data_sc.zip\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from MapTS import GetFs,GetBoundary,GetDt\n",
        "from manipulate import Manipulator\n",
        "\n",
        "# 3.CLIPのモデル化\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# 4.モデルに学習済みパラメータをロード\n",
        "M=Manipulator(dataset_name='ffhq')\n",
        "fs3=np.load('./npy/ffhq/fs3.npy')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbN_I_LIOOgr"
      },
      "source": [
        "# 顔画像の切り出し"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBC64FG4Rdux"
      },
      "source": [
        "# --- 画像表示関数 ---\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        if file=='.ipynb_checkpoints':\n",
        "           continue\n",
        "        img = Image.open(folder+'/'+file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(folder+'/'+file, fontsize=15)               \n",
        "    plt.show()\n",
        "    plt.close()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_mHMjhLRxep"
      },
      "source": [
        "# --- サンプル画像表示 ---\n",
        "display_pic('images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ld45KbIF45C"
      },
      "source": [
        "# --- 顔画像の切り出し ---\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "if os.path.isdir('align'):\n",
        "     shutil.rmtree('align')\n",
        "os.makedirs('align', exist_ok=True)\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  import dlib\n",
        "  from utils.alignment import align_face\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor) \n",
        "  return aligned_image \n",
        "\n",
        "files = sorted(os.listdir('./images'))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = run_alignment('./images/'+file)\n",
        "  input_image.resize((256,256))\n",
        "  input_image.save('./align/'+file)\n",
        "\n",
        "display_pic('align')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsgmDCzVOZHy"
      },
      "source": [
        "# 潜在変数の推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxbCdavcfXNd"
      },
      "source": [
        "# --- 潜在変数の推定 ---\n",
        "if os.path.isdir('vec_pic'):\n",
        "     shutil.rmtree('vec_pic')\n",
        "os.makedirs('vec_pic', exist_ok=True)\n",
        "\n",
        "if os.path.isdir('vec'):\n",
        "     shutil.rmtree('vec')\n",
        "os.makedirs('vec', exist_ok=True)\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "files = sorted(os.listdir('./align'))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = Image.open('./align/'+file)\n",
        "  transformed_image = img_transforms(input_image)\n",
        "  with torch.no_grad():\n",
        "     images, latents = net(transformed_image.unsqueeze(0).to('cuda').float(), randomize_noise=False, return_latents=True)\n",
        "     result_image, latent = images[0], latents[0]\n",
        "     tensor2im(result_image).save('./vec_pic/'+file) \n",
        "     torch.save(latents, './vec/'+file[:-4]+'.pt') \n",
        "\n",
        "display_pic('vec_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvA3EJXX3ZxH"
      },
      "source": [
        "# --- 実写と潜在変数の比較 ---\n",
        "display_pic('align')\n",
        "display_pic('vec_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXw0MVRSvV6o"
      },
      "source": [
        "# 潜在変数の編集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG7ZaQnC75qJ"
      },
      "source": [
        "# --- 潜在変数の選択 ---\n",
        "pt_folder = 'vec/'\n",
        "pt_name = '006.pt' #@param {type:\"string\"}\n",
        "latents=torch.load(pt_folder+pt_name)\n",
        "w_plus=latents.cpu().detach().numpy()\n",
        "M.dlatents=M.W2S(w_plus)\n",
        "\n",
        "M.num_images=1\n",
        "M.alpha=[0]\n",
        "M.manipulate_layers=[0]\n",
        "codes,out=M.EditOneC(0,M.dlatents) \n",
        "original=Image.fromarray(out[0,0]).resize((512,512))\n",
        "M.manipulate_layers=None\n",
        "original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1GEXJX82DB"
      },
      "source": [
        "# --- 編集テキスト入力 ---\n",
        "neutral='face with eyes' #@param {type:\"string\"}\n",
        "target='smiling face with eyeglasses' #@param {type:\"string\"}\n",
        "classnames=[target,neutral]\n",
        "dt=GetDt(classnames,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb-oXMon82QR"
      },
      "source": [
        "# --- alpha & beta の設定 ---\n",
        "beta = 0.1 #@param {type:\"slider\", min:0.08, max:0.3, step:0.01}\n",
        "alpha = 3.5 #@param {type:\"slider\", min:-10, max:10, step:0.1}\n",
        "M.alpha=[alpha]\n",
        "boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "codes=M.MSCode(M.dlatents,boundary_tmp2)\n",
        "out=M.GenerateImg(codes)\n",
        "generated=Image.fromarray(out[0,0])#.resize((512,512))\n",
        "generated.save('generated.jpg')\n",
        "\n",
        "plt.figure(figsize=(14,7), dpi= 100)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original)\n",
        "plt.title('original')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(generated)\n",
        "plt.title('manipulated')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcdIARIT6Eeo"
      },
      "source": [
        "# 編集動画の作成\n",
        "alpha を少しづつ変化させ、編集動画を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzJv498B5lXO"
      },
      "source": [
        "# --- 編集画像の連続生成 ---\n",
        "max_alpha = 3.5 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "num = int(max_alpha*10)\n",
        "beta = 0.1\n",
        "\n",
        "from tqdm import trange\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# pic フォルダーリセット\n",
        "if os.path.isdir('pic'):\n",
        "     shutil.rmtree('pic')\n",
        "os.makedirs('pic', exist_ok=True)\n",
        "\n",
        "def generate_img(alpha, cnt):\n",
        "     M.alpha=[alpha]\n",
        "     boundary_tmp2,c=GetBoundary(fs3,dt,M,threshold=beta)\n",
        "     codes=M.MSCode(M.dlatents, boundary_tmp2)\n",
        "     out=M.GenerateImg(codes)\n",
        "     pic = Image.fromarray(out[0,0])\n",
        "     pic = pic.resize((512,512))  \n",
        "\n",
        "     dst = Image.new('RGB', (original.width + pic.width, original.height))\n",
        "     dst.paste(original, (0,0))\n",
        "     dst.paste(pic, (original.width, 0))\n",
        "\n",
        "     dst.save('./pic/'+str(cnt).zfill(6)+'.png')   \n",
        "\n",
        "cnt = 0\n",
        "for i in trange(15, desc='alpha = 0'):\n",
        "     generate_img(0, cnt)\n",
        "     cnt +=1\n",
        "\n",
        "for i in trange(0, num, 1, desc='alpha = 0 -> max'):\n",
        "     generate_img(i/10, cnt)\n",
        "     cnt +=1\n",
        "\n",
        "for i in trange(60, desc='alpha = max'):\n",
        "     generate_img(num/10, cnt)\n",
        "     cnt +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESrZ4La85yZd"
      },
      "source": [
        "# --- mp4動画の作成 ---\n",
        "# 既に output.mp4 があれば削除する\n",
        "import os\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "! ffmpeg -r 30 -i pic/%6d.png\\\n",
        "               -vcodec libx264 -pix_fmt yuv420p output.mp4\n",
        "\n",
        "# movieフォルダへ名前を付けてコピー\n",
        "import shutil\n",
        "os.makedirs('movie', exist_ok=True)\n",
        "shutil.copy('output.mp4', 'movie/'+target+'_'+pt_name[:-3]+'.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54VRA0m535O"
      },
      "source": [
        "# --- mp4動画の再生 ---\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"70%\" height=\"70%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}